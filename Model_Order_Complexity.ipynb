{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for understanding and exploring Model Order Complexity\n",
    "\n",
    "In Model Order Selection (MOS) problems we are trying to find a model structure that fit the task at hand. This is a very important step in machine learning as it is crucial to have a generalizable model.  \n",
    "In general we want a model able to capture the data complexity. Given some data drawn from a distribution, how do we relate model complexity to it? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variance \n",
    "\n",
    "Variance is to be thought of as how much our model will vary depending on the data. So for instance, if we draw some subset of data from a distribution and fit a very complex model to it, it might perform well on that data. However, if the distribution we draw our data from has somewhat high variance, our subsample might look very different. Then, our model will perform poorly, due to the model now fitting the previous data well. Another way of seeing it, if we change our data somewhat, our model changes alot.  \n",
    "This proposes a relationship between data variance and model complexity, where increasing complexity increase the variance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias \n",
    "\n",
    "When drawing data from a distribution to estimate some variable, we expect there to be some deviation between the true variable value and the estimated one. This difference is the bias, so its the expected value of the deviation between our estimate and ground truth. This can be viewed as an intrinsic error our model is not able to remove.  \n",
    "\n",
    "If imagening the true estimate is a 3 dimensional value, if our model produce an estimate that is 2 dimensional, there will be a minimal difference equal to the projection down to 2D. Increasing the model complexity lets us estimate a 3 dimesnional estimate and \"bridge\" this gap. So we expect increasing model complexity to decrease the bias. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The tradeoff\n",
    "\n",
    "When speeking of MOS problems and the Bias-Variance-tradeoff we think of how changing model complexity will affect the expected performance. \n",
    "\n",
    "To high complexity reduce the Bias, meaning we are *able* to estimate more correctly. However, the estimate becomes more specific to the data drawn from the distribution rather than to the underlying distribution. At the same time, high complexity gives high variance, so changing the data a bit will change our model alot. Even though the data is drawn from the same distribution.  \n",
    "This is whats called **overfitting**, our model performs well on seen data, but not new. We say it doesnt generalize and failt to capture the underlying distribution. \n",
    "\n",
    "Conversly, too low complexity reduce the model variance. We might think the model is forced to capture only the general structure of the data, which is roughly the same between different samples of the same distribution. However, the bias increase, making our best estimate diverge away from the true value. This is called **underfitting**\n",
    "\n",
    "\n",
    "One way to see the tradeoff is considering a common least squares problem of minimizing, assuming normal distributed with zero mean.   \n",
    "$$(\\theta - \\hat{\\theta})^2$$\n",
    "\n",
    "We could pose this as minimizing the expected value of this difference, as this results in the same minimization problem, minimize:\n",
    " $$E[(\\theta - \\hat{\\theta})^2 ]$$\n",
    "\n",
    " This leads to the derivation \n",
    "\n",
    "  $$E[(\\theta - \\hat{\\theta})^2 ] = E[\\theta^2 - 2 \\theta \\hat{\\theta} - \\hat{\\theta}^2] = E[\\theta ^2] -2E[\\theta \\hat{\\theta}] + E[\\hat{\\theta}^2]$$\n",
    "\n",
    "  These terms can be rearanged \n",
    "\n",
    "  $$E[\\theta^2] = E[(f + \\epsilon)^2] = E[f^2] + 2*f*E[\\epsilon] + E[\\epsilon ^2] = f^2 + 0 + \\sigma^2$$\n",
    "  $$E[\\theta \\hat{\\theta}] = E[(f + \\epsilon)\\hat{\\theta}] = fE[\\hat{\\theta}]$$\n",
    "  $$E[\\hat{\\theta}^2]=Var[\\hat{\\theta}] + E[\\hat{\\theta}]^2$$\n",
    "\n",
    "  Now plugging these into the formula above we get, generally \n",
    "\n",
    "  $$MSE = Bias[\\hat{\\theta}]^2 + Variance[\\hat{\\theta}]$$\n",
    "\n",
    "  So this propose that there is some minimum to the MSE that is where the Bias and Variance meet. \n",
    "\n",
    "![](./images/biasvariance.png \"Bias Variance Tradeoff\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exam Question: \n",
    "\n",
    "**What do we expect to see when training and testing different estimators with different model order complexities? How should we account for the effects that we see on the statistical performance indexes?**\n",
    "\n",
    "When training different estimators with different model order complexities, it could be difficult to directly measure the bias and variance tradeoff. It could however be compared within the same estimator with varying complexities. \n",
    "\n",
    "When changing the complexity of our model, we expect to see the loss change in some way. This is how we move along the above curve, moving along the bias variance tradeoff. So we expect to have decreasing error in the beginning as we decrease the bias whilst the variance becomes apropriate for the data. At some point, we go past this point where errors start increasing. At this point, our model is able to diminish the bias, however becomes to prone to details in the data to capture the underlying structure. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ockham's razor \n",
    "Ochkham's razor is a concept saying we want to explain anything as simple as possible without loosing the essential information about the thing we explain. \n",
    "\n",
    "In context of Model Order selection we usually think that a simpler model is better as it wont overfit to data as easily. However, it is still important to not make the model too simple so it looses information about the data. \n",
    "\n",
    "One way we often determine when we go too far is by the \"broken stick\" or \"elbow\" method. Where we vary the model order and look at the performance. Usually it steadily gets better, but at some point this halts, and we get a bend in the trend. Such methods are often employed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
